import asyncio
import aiodns
import re
import os
import json
import logging
import ipaddress
import io
import uuid
import string
import socket
import base64

from enum import Enum
from urllib.parse import urlparse, parse_qs, quote_plus, urlsplit
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set
from dataclasses import dataclass, field, astuple, replace
from collections import defaultdict

import aiohttp

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
LOG_FORMAT = "%(asctime)s [%(levelname)s] %(message)s"
CONSOLE_LOG_FORMAT = "[%(levelname)s] %(message)s"
LOG_FILE = 'proxy_checker.log'

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

file_handler = logging.FileHandler(LOG_FILE, encoding='utf-8')
file_handler.setLevel(logging.WARNING)
formatter_file = logging.Formatter(LOG_FORMAT)
file_handler.setFormatter(formatter_file)
logger.addHandler(file_handler)

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
formatter_console = logging.Formatter(CONSOLE_LOG_FORMAT)
console_handler.setFormatter(formatter_console)
logger.addHandler(console_handler)


# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
DEFAULT_SCORING_WEIGHTS_FILE = "configs/scoring_weights.json"
ALLOWED_PROTOCOLS = ["vless://", "ss://", "trojan://", "tuic://", "hy2://", "ssconf://"]
MAX_CONCURRENT_CHANNELS = 90
MAX_CONCURRENT_PROXIES_PER_CHANNEL = 120
MAX_CONCURRENT_PROXIES_GLOBAL = 120
OUTPUT_CONFIG_FILE = "configs/proxy_configs.txt"
ALL_URLS_FILE = "all_urls.txt"
PROTOCOL_TIMEOUT = 4.0
SOURCE_URL_TIMEOUT = 10.0


# --- –ò—Å–∫–ª—é—á–µ–Ω–∏—è ---
class InvalidURLError(ValueError):
    pass

class UnsupportedProtocolError(ValueError):
    pass

class ConfigParseError(ValueError):
    pass


# --- Data classes –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π (–º–∏–Ω–∏–º—É–º –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞) ---
@dataclass(frozen=True)
class VlessConfig:
    uuid: str
    address: str
    port: int

    @classmethod
    async def from_url(cls, parsed_url: urlparse, query: Dict, resolver: aiodns.DNSResolver) -> "VlessConfig":
        address = await resolve_address(parsed_url.hostname, resolver)
        return cls(
            uuid=parsed_url.username,
            address=address,
            port=parsed_url.port,
        )

@dataclass(frozen=True)
class SSConfig:
    method: str
    password: str
    address: str
    port: int

    @classmethod
    async def from_url(cls, parsed_url: urlparse, query: Dict, resolver: aiodns.DNSResolver) -> "SSConfig":
        address = await resolve_address(parsed_url.hostname, resolver)
        return cls(
            method=parsed_url.username.lower() if parsed_url.username else 'none',
            password=parsed_url.password,
            address=address,
            port=parsed_url.port,
        )

@dataclass(frozen=True)
class TrojanConfig:
    password: str
    address: str
    port: int

    @classmethod
    async def from_url(cls, parsed_url: urlparse, query: Dict, resolver: aiodns.DNSResolver) -> "TrojanConfig":
        address = await resolve_address(parsed_url.hostname, resolver)
        return cls(
            password=parsed_url.password,
            address=address,
            port=parsed_url.port,
        )

@dataclass(frozen=True)
class TuicConfig:
    uuid: str
    address: str
    port: int

    @classmethod
    async def from_url(cls, parsed_url: urlparse, query: Dict, resolver: aiodns.DNSResolver) -> "TuicConfig":
        address = await resolve_address(parsed_url.hostname, resolver)
        return cls(
            uuid=parsed_url.username,
            address=address,
            port=parsed_url.port,
        )

@dataclass(frozen=True)
class Hy2Config:
    password: str
    address: str
    port: int

    @classmethod
    async def from_url(cls, parsed_url: urlparse, query: Dict, resolver: aiodns.DNSResolver) -> "Hy2Config":
        address = await resolve_address(parsed_url.hostname, resolver)
        return cls(
            password=parsed_url.password,
            address=address,
            port=parsed_url.port,
        )

@dataclass(frozen=True)
class SSConfConfig:
    server: str
    server_port: int
    password: str
    method: str

    @classmethod
    async def from_url(cls, config_string: str, resolver: aiodns.DNSResolver) -> "SSConfConfig":
        try:
            config_b64 = config_string.split("ssconf://")[1]
            config_json_str = base64.urlsafe_b64decode(config_b64 + '=' * (4 - len(config_b64) % 4)).decode('utf-8')
            config_json = json.loads(config_json_str)
            return cls(
                server=config_json.get('server'),
                server_port=int(config_json.get('server_port')),
                password=config_json.get('password'),
                method=config_json.get('method')
            )
        except json.JSONDecodeError as e:
            raise ConfigParseError(f"JSON decode error: {e}")
        except KeyError as e:
            raise ConfigParseError(f"Missing key in config: {e}")


# --- Data classes –¥–ª—è –º–µ—Ç—Ä–∏–∫ –∏ –∫–∞–Ω–∞–ª–æ–≤ ---
@dataclass
class ChannelMetrics:
    valid_configs: int = 0
    protocol_counts: Dict[str, int] = field(default_factory=lambda: defaultdict(int))

class ChannelConfig:
    VALID_PROTOCOLS_SOURCE = ["https://", "http://"]
    VALID_PROTOCOLS_PROXY = ALLOWED_PROTOCOLS

    def __init__(self, url: str):
        self.url = self._validate_url(url)
        self.metrics = ChannelMetrics()

    def _validate_url(self, url: str) -> str:
        parsed = urlsplit(url)
        if parsed.scheme not in [p.replace('://', '') for p in self.VALID_PROTOCOLS_SOURCE]:
            expected_protocols = ', '.join(self.VALID_PROTOCOLS_SOURCE)
            received_protocol_prefix = parsed.scheme or url[:10]
            raise UnsupportedProtocolError(
                f"–ù–µ–≤–µ—Ä–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞. –û–∂–∏–¥–∞–µ—Ç—Å—è: {expected_protocols}, –ø–æ–ª—É—á–µ–Ω–æ: {received_protocol_prefix}..."
            )
        return url



class ProxyConfig:
    def __init__(self):
        os.makedirs(os.path.dirname(OUTPUT_CONFIG_FILE), exist_ok=True)
        self.resolver = None
        self.SOURCE_URLS = self._load_source_urls()
        self.OUTPUT_FILE = OUTPUT_CONFIG_FILE
        self.ALL_URLS_FILE = ALL_URLS_FILE

    def _load_source_urls(self) -> List[ChannelConfig]:
        initial_urls = []
        try:
            with open(ALL_URLS_FILE, 'r', encoding='utf-8') as f:
                for line in f:
                    url = line.strip()
                    if url:
                        try:
                            initial_urls.append(ChannelConfig(url))
                        except (InvalidURLError, UnsupportedProtocolError) as e:
                            logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π URL –≤ {ALL_URLS_FILE}: {url} - {e}. –û–∂–∏–¥–∞–µ—Ç—Å—è URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (http/https).")
        except FileNotFoundError:
            logger.warning(f"–§–∞–π–ª URL –Ω–µ –Ω–∞–π–¥–µ–Ω: {ALL_URLS_FILE}. –°–æ–∑–¥–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª.")
            open(ALL_URLS_FILE, 'w', encoding='utf-8').close()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {ALL_URLS_FILE}: {e}")
        return initial_urls

    def get_enabled_channels(self) -> List[ChannelConfig]:
        return self.SOURCE_URLS

    def save_empty_config_file(self) -> bool:
        try:
            with open(OUTPUT_CONFIG_FILE, 'w', encoding='utf-8') as f:
                f.write("")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            return False

    def set_event_loop(self, loop):
        self.resolver = aiodns.DNSResolver(loop=loop)


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
async def resolve_address(hostname: str, resolver: aiodns.DNSResolver) -> str:
    if is_valid_ipv4(hostname) or is_valid_ipv6(hostname):
        return hostname
    try:
        result = await resolver.query(hostname, 'A')
        return result[0].host
    except aiodns.error.DNSError as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑—Ä–µ—à–∏—Ç—å hostname: {hostname} - {e}")
        return hostname
    except Exception as e:
        logger.warning(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–∑–æ–ª–≤–∏–Ω–≥–µ {hostname}: {e}")
        return hostname

def is_valid_ipv4(hostname: str) -> bool:
    try:
        ipaddress.IPv4Address(hostname)
        return True
    except ipaddress.AddressValueError:
        return False

def is_valid_ipv6(hostname: str) -> bool:
    try:
        ipaddress.IPv6Address(hostname)
        return True
    except ipaddress.AddressValueError:
        return False

def is_valid_proxy_url(url: str) -> bool:
    if not any(url.startswith(protocol) for protocol in ALLOWED_PROTOCOLS):
        return False
    try:
        parsed = urlparse(url)
        if not parsed.hostname or not parsed.port:
            return False
        return True
    except ValueError:
        return False


async def parse_config(config_string: str, resolver: aiodns.DNSResolver) -> Optional[object]:
    protocol = next((p for p in ALLOWED_PROTOCOLS if config_string.startswith(p)), None)
    if not protocol:
        return None

    try:
        parsed = urlparse(config_string)
        query = parse_qs(parsed.query)
        scheme = parsed.scheme

        config_parsers = {
            "vless": VlessConfig.from_url,
            "ss": SSConfig.from_url,
            "trojan": TrojanConfig.from_url,
            "tuic": TuicConfig.from_url,
            "hy2": Hy2Config.from_url,
            "ssconf": SSConfConfig.from_url, # ssconf does not use urlparse directly for parsing
        }
        if scheme in config_parsers:
            if scheme == "ssconf":
                return await config_parsers[scheme](config_string, resolver) # Pass full string for ssconf
            else:
                return await config_parsers[scheme](parsed, query, resolver)
        return None

    except (InvalidURLError, UnsupportedProtocolError, ConfigParseError) as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {config_string} - {e}")
        return None
    except Exception as e:
        logger.exception(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_string}: {e}")
        return None


# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ ---
async def test_connection(host: str, port: int, timeout: float, protocol_name: str) -> bool:
    try:
        await asyncio.wait_for(asyncio.open_connection(host=host, port=port), timeout=timeout)
        logger.debug(f"‚úÖ {protocol_name} –ø—Ä–æ–≤–µ—Ä–∫–∞: TCP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å {host}:{port} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–∞ {timeout:.2f} —Å–µ–∫—É–Ω–¥.")
        return True
    except asyncio.TimeoutError:
        logger.debug(f"‚ùå {protocol_name} –ø—Ä–æ–≤–µ—Ä–∫–∞: TCP —Ç–∞–π–º–∞—É—Ç ({timeout:.2f} —Å–µ–∫) –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ {host}:{port}.")
        return False
    except (ConnectionRefusedError, OSError, socket.gaierror) as e:
        logger.debug(f"‚ùå {protocol_name} –ø—Ä–æ–≤–µ—Ä–∫–∞: –û—à–∏–±–∫–∞ TCP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å {host}:{port}: {e}.")
        return False


async def process_single_proxy(line: str, channel: ChannelConfig,
                              proxy_config: ProxyConfig,
                              proxy_semaphore: asyncio.Semaphore,
                              global_proxy_semaphore: asyncio.Semaphore) -> Optional[Dict]:
    async with proxy_semaphore, global_proxy_semaphore:
        config_obj = await parse_config(line, proxy_config.resolver)
        if config_obj is None:
            return None

        protocol_type = config_obj.__class__.__name__.replace("Config", "").lower()
        is_reachable = False

        if protocol_type in ["vless", "trojan", "ss", "tuic", "hy2"]:
            is_reachable = await test_connection(config_obj.address, config_obj.port, PROTOCOL_TIMEOUT, protocol_type.upper())
        elif protocol_type == "ssconf":
            is_reachable = await test_connection(config_obj.server, config_obj.server_port, PROTOCOL_TIMEOUT, protocol_type.upper())
        else:
            logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {protocol_type}")
            return None

        if not is_reachable:
            return None

        result = {
            "config": line,
            "protocol": protocol_type,
            "config_obj": config_obj
        }
        channel.metrics.protocol_counts[protocol_type] += 1
        return result


async def process_all_channels(channels: List["ChannelConfig"], proxy_config: "ProxyConfig") -> List[Dict]:
    channel_semaphore = asyncio.Semaphore(MAX_CONCURRENT_CHANNELS)
    global_proxy_semaphore = asyncio.Semaphore(MAX_CONCURRENT_PROXIES_GLOBAL)
    proxies_all: List[Dict] = []

    async with aiohttp.ClientSession() as session:
        session_timeout = aiohttp.ClientTimeout(total=SOURCE_URL_TIMEOUT)
        for channel in channels:
            lines = []
            try:
                async with session.get(channel.url, timeout=session_timeout) as response:
                    if response.status == 200:
                        text = await response.text()
                        lines = text.splitlines()
                    else:
                        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ {channel.url}, —Å—Ç–∞—Ç—É—Å: {response.status}")
                        continue
            except aiohttp.ClientError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {channel.url}: {e}")
                continue
            except asyncio.TimeoutError:
                logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {channel.url}")
                continue

            proxy_semaphore = asyncio.Semaphore(MAX_CONCURRENT_PROXIES_PER_CHANNEL)
            proxy_tasks = []

            for line in lines:
                line = line.strip()
                if not line or not any(line.startswith(protocol) for protocol in ALLOWED_PROTOCOLS) or not is_valid_proxy_url(line):
                    continue
                task = asyncio.create_task(process_single_proxy(line, channel, proxy_config,
                                                            proxy_semaphore, global_proxy_semaphore))
                proxy_tasks.append(task)
            results = await asyncio.gather(*proxy_tasks)
            for result in results:
                if result:
                    proxies_all.append(result)
            channel.metrics.valid_configs += len(proxies_all)

    return proxies_all


def save_final_configs(proxies: List[Dict], output_file: str):
    unique_proxies = set()
    unique_proxy_count = 0
    try:
        with io.open(output_file, 'w', encoding='utf-8', buffering=io.DEFAULT_BUFFER_SIZE) as f:
            for proxy in proxies:
                config = proxy['config'].strip()
                parsed = urlparse(config)
                ip_address = parsed.hostname
                port = parsed.port
                protocol = proxy['protocol']
                ip_port_tuple = (ip_address, port, protocol)

                if ip_port_tuple not in unique_proxies:
                    unique_proxies.add(ip_port_tuple)
                    unique_proxy_count += 1
                    f.write(f"{config}\n")
        logger.info(f"–§–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}. –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏: {unique_proxy_count}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {e}")


def main():
    proxy_config = ProxyConfig()
    channels = proxy_config.get_enabled_channels()

    if not channels:
        logger.error("–ù–µ—Ç URL –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ URL –≤ all_urls.txt")
        proxy_config.save_empty_config_file()
        return

    async def runner():
        loop = asyncio.get_running_loop()
        proxy_config.set_event_loop(loop)

        logger.info("üöÄ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–∫—Å–∏...")
        proxies = await process_all_channels(channels, proxy_config)

        if not proxies:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π.")
            proxy_config.save_empty_config_file()
        else:
            save_final_configs(proxies, proxy_config.OUTPUT_FILE)

        total_channels = len(channels)
        enabled_channels = total_channels
        disabled_channels = 0 # No disable logic in this version
        total_valid_configs = sum(channel.metrics.valid_configs for channel in channels)

        protocol_stats = defaultdict(int)
        for channel in channels:
            for protocol, count in channel.metrics.protocol_counts.items():
                protocol_stats[protocol] += count

        logger.info("==================== üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–í–ï–†–ö–ò –ü–†–û–ö–°–ò ====================")
        logger.info(f"üîÑ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤-–∫–∞–Ω–∞–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_channels}")
        logger.info(f"‚úÖ –í–∫–ª—é—á–µ–Ω–æ —Ñ–∞–π–ª–æ–≤-–∫–∞–Ω–∞–ª–æ–≤: {enabled_channels}")
        logger.info(f"‚ùå –û—Ç–∫–ª—é—á–µ–Ω–æ —Ñ–∞–π–ª–æ–≤-–∫–∞–Ω–∞–ª–æ–≤: {disabled_channels}")
        logger.info(f"‚ú® –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π: {total_valid_configs}")

        logger.info("\n breakdown by protocol:")
        if protocol_stats:
            for protocol, count in protocol_stats.items():
                logger.info(f"   - {protocol}: {count} configs")
        else:
            logger.info("   No protocol statistics available.")

        logger.info("======================== üèÅ –ö–û–ù–ï–¶ –°–¢–ê–¢–ò–°–¢–ò–ö–ò =========================")
        logger.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∫—Å–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


    asyncio.run(runner())


if __name__ == "__main__":
    main()
